# -*- coding: utf-8 -*-
"""LoanEligibility.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KEm4x8yftB5iO3xmiAQ2ZwhfwU9ttDYS
"""

# Commented out IPython magic to ensure Python compatibility.
#importing the libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline

#uploading and exploring the train dataset
train = pd.read_csv('/content/drive/MyDrive/Loan Eligibility Prediction/train_u6lujuX_CVtuZ9i.csv')
train.head()

#describing the dataset
train.describe()

#finding out how many missing values are present in the dataset
train.isnull().sum()

#analysing how the credit history affects the loan status of an applicant
pd.crosstab(train['Credit_History'],train['Loan_Status'])
#we can see that an applicant with credit history of 1 are more eligible for loan than an applicant with credit history of 0.

#analysing how the applicant income affects the loan status of an applicant
train.hist(['ApplicantIncome'])
#we can see that the data is right skewed, which we have to later normalize

#analysing how the applicant's income is related to education
train.boxplot(column='ApplicantIncome', by='Education')

#analysing how the loan amount affects the loan status of an applicant
train.hist(['LoanAmount'])
##we can see that the data is right skewed, which we have to later normalize

#we have to normalize the features like ApplicantIncome and LoanAmount to improve the performance of the model, as normalizing will help put all the features on the same scale.
#for normalizing we apply the log function
train['LoanAmount_log']=np.log(train['LoanAmount'])
train.hist(['LoanAmount_log'])

#for normalizing we apply the log function
train['TotalIncome']=train['ApplicantIncome']+train['CoapplicantIncome'] #we normalize the ApplicantIncome and CoapplicantIncome together as TotalIncome
train['TotalIncome_log']=np.log(train['TotalIncome'])
train.hist(['TotalIncome_log'])

#filling out the null values in the dataset
train['Gender'].fillna(train['Gender'].mode()[0],inplace=True) #since Gender is a categorical data we use mode function to fill the null values and inplace function to replace the null values with mode value
train['Married'].fillna(train['Married'].mode()[0],inplace=True) #same goes for Married
train['Dependents'].fillna(train['Dependents'].mode()[0],inplace=True) #same goes for Dependents
train['Self_Employed'].fillna(train['Self_Employed'].mode()[0],inplace=True) #same goes for Self Employed
train['Credit_History'].fillna(train['Credit_History'].mode()[0],inplace=True) #same goes for Credit History
train['Loan_Amount_Term'].fillna(train['Loan_Amount_Term'].mode()[0],inplace=True) #same goes for Loan Amount Term
train['LoanAmount'].fillna(train['LoanAmount'].mean(),inplace=True) #since Loan Amount is a continuous data we use mean function to fill the null values and inplace function to replace the null values with mean value
train['LoanAmount_log'].fillna(train['LoanAmount_log'].mean(),inplace=True) #Loan Amount log is a continuos data we use mean function to fill the null values and inplace function to replace the null values with mean value

#checking whether the missing values still exist or not
train.isnull().sum()

#Dividing the train dataset into dependent and independent variables
X = train.iloc[:,np.r_[1:5,9:11,13:15]].values
y = train.iloc[:,12].values
#values function will convert the selected column(s) into a NumPy array

#split the dataset using train_test_split
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0) #set the random state to 0 to get same result every time a code runs.
print(X_train)

#convert the categorical data into numeric form using LabelEncoder
from sklearn.preprocessing import LabelEncoder
#create an instance for X
labelencoder_X = LabelEncoder()
for i in range(0,5):
  X_train[:,i]=labelencoder_X.fit_transform( X_train[:,i])
  X_train[:,7]=labelencoder_X.fit_transform( X_train[:,7])
print(X_train)

#create an instance for y
labelencoder_y = LabelEncoder()
y_train=labelencoder_y.fit_transform( y_train)
print(y_train)

#do the same for test data
labelencoder_X = LabelEncoder()
for i in range(0,5):
  X_test[:,i]=labelencoder_X.fit_transform( X_test[:,i]) #the indices will remain same because the data is same for both train set and test set
  X_test[:,7]=labelencoder_X.fit_transform( X_test[:,7])
print(X_test)

labelencoder_y = LabelEncoder()
y_test=labelencoder_y.fit_transform( y_test)
print(y_test)

#scaling the data
from sklearn.preprocessing import StandardScaler
scale = StandardScaler()
X_train = scale.fit_transform(X_train)
X_test = scale.fit_transform(X_test)

#Now after all the data preprocessing has been done, we have to apply the Machine Learning Algorithm.
from sklearn.naive_bayes import GaussianNB
NbClassifier = GaussianNB()
NbClassifier.fit(X_train,y_train)
#check the accuracy of the algorithm
y_pred = NbClassifier.predict(X_test)
print(y_pred)
from sklearn import metrics
print('The accuracy of Naive Bayes Classification Model is: ', metrics.accuracy_score(y_pred,y_test))
#The accuracy is nearly 83%

#We have to check this algorithm on Test dataset to predict the outcome whether an applicant is eligible for loan or not.
test = pd.read_csv('/content/drive/MyDrive/Loan Eligibility Prediction/test_Y3wMUE5_7gLdaTN.csv')
test.head()

#finding out how many missing values are present in the dataset
test.isnull().sum()



#filling out the null values in the dataset
test['Gender'].fillna(test['Gender'].mode()[0],inplace=True)
test['Married'].fillna(test['Married'].mode()[0],inplace=True)
test['Dependents'].fillna(test['Dependents'].mode()[0],inplace=True)
test['Self_Employed'].fillna(test['Self_Employed'].mode()[0],inplace=True)
test['Credit_History'].fillna(test['Credit_History'].mode()[0],inplace=True)
test['Loan_Amount_Term'].fillna(test['Loan_Amount_Term'].mode()[0],inplace=True)
test['LoanAmount'].fillna(test['LoanAmount'].mean(),inplace=True)

#checking whether the missing values still exist or not
test.isnull().sum()

#for normalizing we apply the log function
test['TotalIncome']=test['ApplicantIncome']+test['CoapplicantIncome'] #we normalize the ApplicantIncome and CoapplicantIncome together as TotalIncome
test['TotalIncome_log']=np.log(test['TotalIncome'])
test.hist(['TotalIncome_log'])



#converting the categorical data into numeric form using LabelEncoder
t = test.iloc[:,np.r_[1:5,9:11,12:14]].values #here we use 12:14 inplace of 13:15 becuase test dataset has only 14 columns so using 13:15 will throw IndexError: position indexers are out-of-bounds.
for i in range(0,5):
  t[:,i]=labelencoder_X.fit_transform( t[:,i])
  t[:,7]=labelencoder_X.fit_transform( t[:,7])
print(t)

#scaling the data
t = scale.fit_transform(t)

#Finally!!! let's predict the outcome
pred = NbClassifier.predict(t)
print(pred)
#Here 1 represents that a customer is eligible for the loan and 0 represents that a customer is not eligible for the loan.